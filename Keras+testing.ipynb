{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Convolution1D, MaxPooling1D, AveragePooling1D, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from keras.layers import Embedding, LSTM, Input, Merge, Dense, TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_word_len=3\n",
    "max_seq_len=5\n",
    "w_embed_size=6\n",
    "c_embed_size=3\n",
    "max_chars=2\n",
    "max_words=20\n",
    "c_nb_filters=4\n",
    "c_filter_length=3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "char_cnn_layer=Sequential()\n",
    "char_cnn_layer.add(Embedding(max_chars, c_embed_size, input_length=max_word_len, name=\"char_embed\"))\n",
    "char_cnn_layer.add(Convolution1D(c_nb_filters,c_filter_length, activation='relu'))\n",
    "char_cnn_layer.add(GlobalAveragePooling1D(name=\"char_based_word_embed\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((None, 4), (None, 3))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_cnn_layer.output_shape, char_cnn_layer.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "char_embed (Embedding)           (None, 3, 3)          6           embedding_input_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_1 (Convolution1D)  (None, 1, 4)          40          char_embed[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "char_based_word_embed (GlobalAve (None, 4)             0           convolution1d_1[0][0]            \n",
      "====================================================================================================\n",
      "Total params: 46\n",
      "Trainable params: 46\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "char_cnn_layer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "tdcnn (TimeDistributed)          (None, 5, 4)          46          timedistributed_input_1[0][0]    \n",
      "====================================================================================================\n",
      "Total params: 46\n",
      "Trainable params: 46\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "char_seq_layer=Sequential()\n",
    "char_seq_layer.add(TimeDistributed(char_cnn_layer, input_shape=(max_seq_len, max_word_len), name=\"tdcnn\"))\n",
    "char_seq_layer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "word_embed (Embedding)           (None, 5, 6)          120         embedding_input_2[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 120\n",
      "Trainable params: 120\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "word_seq_layer=Sequential()\n",
    "word_seq_layer.add(Embedding(max_words, w_embed_size, input_length=max_seq_len, name=\"word_embed\"))\n",
    "word_seq_layer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "tdcnn (TimeDistributed)          (None, 5, 4)          46          timedistributed_input_1[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "word_embed (Embedding)           (None, 5, 6)          120         embedding_input_2[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "shared_lstm (LSTM)               (None, 5, 10)         840         char_word_embedding[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_1 (TimeDistribut (None, 5, 1)          11          shared_lstm[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 1,017\n",
      "Trainable params: 1,017\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "full_seq_layer=Sequential()\n",
    "full_seq_layer.add(Merge([char_seq_layer, word_seq_layer], mode=\"concat\", name=\"char_word_embedding\"))\n",
    "full_seq_layer.add(LSTM(10, return_sequences=True, name=\"shared_lstm\"))\n",
    "full_seq_layer.add(TimeDistributed(Dense(1, activation='sigmoid')))\n",
    "full_seq_layer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_seq_layer.compile(loss='sparse_categorical_crossentropy', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 5, 3), (None, 5)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_seq_layer.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 5, 3), (2, 5))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_words = [\n",
    "    [1,2,1,4,5],\n",
    "    [1,2,1,4,5]\n",
    "          ]\n",
    "X_chars = [\n",
    "    [\n",
    "        [0,1,0],\n",
    "        [0,1,1],\n",
    "        [0,1,0],\n",
    "        [1,1,0],\n",
    "        [0,1,0]\n",
    "    ],\n",
    "    [\n",
    "        [0,1,1],\n",
    "        [0,1,1],\n",
    "        [0,1,0],\n",
    "        [0,0,0],\n",
    "        [0,1,0]\n",
    "    ]\n",
    "          ]\n",
    "X_words = np.array(X_words)\n",
    "X_chars = np.array(X_chars)\n",
    "X_chars.shape, X_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 5, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = [\n",
    "    [0, 1, 1, 1, 0],\n",
    "    [0, 0, 0, 1, 0]\n",
    "]\n",
    "y = np.expand_dims(np.array(y), -1)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 7s - loss: nan\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s - loss: nan\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s - loss: nan\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s - loss: nan\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s - loss: nan\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s - loss: nan\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s - loss: nan\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s - loss: nan\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s - loss: nan\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s - loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6641411da0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_seq_layer.fit([X_chars, X_words], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
