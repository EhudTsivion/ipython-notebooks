{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Author Topic Model\n",
    "\n",
    "Implementation as described in http://mimno.infosci.cornell.edu/info6150/readings/398.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  7.  7.  7.  5.]\n",
      " [ 1.  7.  5.  1.  0.]\n",
      " [ 5.  5.  6.  9.  2.]\n",
      " [ 4.  6.  0.  7.  2.]]\n",
      "[1 2 1 2 3]\n",
      "['V0' 'V1' 'V2' 'V3' 'V4' 'V5' 'V6' 'V7' 'V8' 'V9']\n",
      "[[  0.  14.   7.  14.  15.]\n",
      " [  1.  14.   5.   2.   0.]\n",
      " [  5.  10.   6.  18.   6.]\n",
      " [  4.  12.   0.  14.   6.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['V2', 'V1', 'V0', 'V2', 'V0'],\n",
       "       ['V3', 'V0', 'V2', 'V3', 'V3']], \n",
       "      dtype='|S2')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones([10])[[2,3,4], np.newaxis].repeat(5, axis=1)\n",
    "\n",
    "_a = np.random.randint(0,10,size=(4,5)) * 1.0\n",
    "print _a\n",
    "_b = np.array([1,2,1,2,3])\n",
    "print _b\n",
    "_c = np.array([\"V%s\" % k for k in xrange(10)])\n",
    "print _c\n",
    "print (_a * _b)\n",
    "_c[np.argsort(_a, axis=0)[::-1, :][:2, :]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class AuthorTopicModel(object):\n",
    "    \"\"\"Implementation of an author topic model.\n",
    "    Generates each document based on a topic and author pair,\n",
    "    This is used to generate a word in the document.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, K, doc_word_matrix, doc_author_matrix, vocab, authornames, alpha=0.1, beta=0.5):\n",
    "        \"\"\"Constructor for the function\n",
    "        K: number of topics\n",
    "        doc_word_matrix: list of documents each represented as list of word ids\n",
    "        doc_author_matrix: list of documents each represented as list of author ids\n",
    "        vocab: dictionary of word ids mapped to word strings\n",
    "        authornames: dictionary of author ids mapped to author names\n",
    "        alpha: Author topic diritchelet parameter\n",
    "        beta: Word topic diritchelet parameter        \n",
    "        \"\"\"\n",
    "        self.K = K\n",
    "        self.doc_word_matrix = doc_word_matrix\n",
    "        self.doc_author_matrix = doc_author_matrix\n",
    "        self.N = len(doc_word_matrix)\n",
    "        self.vocab = vocab\n",
    "        self.W = len(vocab)\n",
    "        self.authornames= authornames\n",
    "        self.A = len(authornames)\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        \n",
    "        self.W_T = np.zeros([self.W, self.K])\n",
    "        self.A_T = np.zeros([self.A, self.K])\n",
    "        \n",
    "        self.T_marginal = np.zeros(self.K)\n",
    "        self.A_marginal = np.zeros(self.A)\n",
    "        \n",
    "        self.T_assigned = []\n",
    "        self.A_assigned = []\n",
    "        self._populate_vars()\n",
    "        \n",
    "    def _populate_vars(self):\n",
    "        \"\"\"Populate the variables with the initial data\n",
    "        \"\"\"\n",
    "        for di, doc in enumerate(self.doc_word_matrix):\n",
    "            auth = self.doc_author_matrix[di]\n",
    "            self.T_assigned.append([])\n",
    "            self.A_assigned.append([])\n",
    "            for wi, w in enumerate(doc):\n",
    "                # Randomly assign a topic to the word\n",
    "                z = np.random.choice(self.K)\n",
    "                # Randomly assign a topic to a random author\n",
    "                a = np.random.choice(self.A)\n",
    "                # Update all the word, topic and author topic counts\n",
    "                self.W_T[w,z] += 1\n",
    "                self.A_T[a,z] += 1\n",
    "                # Update marginals\n",
    "                self.T_marginal[z] += 1\n",
    "                self.A_marginal[a] += 1\n",
    "                # Record the sampled topic and author assignments\n",
    "                self.T_assigned[-1].append(z)\n",
    "                self.A_assigned[-1].append(a)\n",
    "    \n",
    "    def gibbs_sampling(self):\n",
    "        \"\"\"Perform single gibbs sampling step\n",
    "        \"\"\"\n",
    "        for di, doc in enumerate(self.doc_word_matrix):\n",
    "            auth = self.doc_author_matrix[di]\n",
    "            for wi, w in enumerate(doc):\n",
    "                # Extract the previous assignment\n",
    "                z = self.T_assigned[di][wi]\n",
    "                a = self.A_assigned[di][wi]\n",
    "                # Substract the previous assignments\n",
    "                # Update all the word, topic and author topic counts\n",
    "                self.W_T[w,z] -= 1\n",
    "                self.A_T[a,z] -= 1\n",
    "                # Update marginals\n",
    "                self.T_marginal[z] -= 1\n",
    "                self.A_marginal[a] -= 1\n",
    "                \n",
    "                # Find probability of the word w belonging to each topic\n",
    "                phi = (self.W_T[w,:] + self.beta) / (self.T_marginal + self.W*self.beta)\n",
    "                # Find probability of each author in auth belonging to each topic\n",
    "                theta = (self.A_T[auth,:] + self.alpha) / (self.A_marginal[auth, np.newaxis] + self.W*self.alpha)\n",
    "                # Joint probability of word and author for all topics\n",
    "                pdf = theta*phi\n",
    "                pdf = pdf / pdf.sum()\n",
    "                # Index of authors and topics\n",
    "                auth_t_pairs = [(i,j) for i in auth for j in xrange(self.K)]\n",
    "                # Sample an author and topic pair for the word\n",
    "                #print auth_t_pairs, p.flatten()\n",
    "                idx = np.random.choice(range(len(auth_t_pairs)), p=pdf.flatten())\n",
    "                a, z = auth_t_pairs[idx]\n",
    "                # Update all the word, topic and author topic counts\n",
    "                self.W_T[w,z] += 1\n",
    "                self.A_T[a,z] += 1\n",
    "                # Update marginals\n",
    "                self.T_marginal[z] += 1\n",
    "                self.A_marginal[a] += 1\n",
    "                # Record the sampled topic and author assignments\n",
    "                self.T_assigned[di][wi] = z\n",
    "                self.A_assigned[di][wi] = a\n",
    "    \n",
    "    def perform_iterations(self, burnin=100, max_iters=10, print_every=5):\n",
    "        \"\"\"Perform max_iters of gibbs sampling steps\n",
    "        \"\"\"\n",
    "        print \"Performing %s gibbs sampling iterations burn in phase\" % burnin\n",
    "        for i in xrange(burnin):\n",
    "            self.gibbs_sampling()\n",
    "        print \"Burn in complete\"\n",
    "        print \"Topic proportions: %s\" % (self.T_marginal * 1. / self.T_marginal.sum())\n",
    "        print \"Author proportions: %s\" % (self.A_marginal * 1. / self.A_marginal.sum())\n",
    "        print \"W_T[w,z]:\\n%s\" % (self.W_T * 1./ self.W_T.sum())\n",
    "        print \"A_T[a,z]:\\n%s\" % (self.A_T * 1./ self.A_T.sum())\n",
    "        print \"Performing %s gibbs sampling iterations\" % max_iters\n",
    "        for i in xrange(max_iters):\n",
    "            if i%print_every == 0:\n",
    "                print \"Iter %s:\" % i\n",
    "                self.gibbs_sampling()\n",
    "                print \"Topic proportions: %s\" % (self.T_marginal * 1. / self.T_marginal.sum())\n",
    "                print \"Author proportions: %s\" % (self.A_marginal * 1. / self.A_marginal.sum())\n",
    "                print \"W_T[w,z]:\\n%s\" % (self.W_T * 1./ self.W_T.sum())\n",
    "                print \"A_T[a,z]:\\n%s\" % (self.A_T * 1./ self.A_T.sum())\n",
    "        print \"Done\"\n",
    "    \n",
    "    def show_topics(self, topn_w=3, topn_a=3):\n",
    "        print \"Top %s words per topic\" % topn_w\n",
    "        print self.vocab[np.argsort(self.W_T, axis=0)[::-1, :][:topn_w, :]]\n",
    "        print \"Top %s authors per topic\" % topn_a\n",
    "        print self.authornames[np.argsort(self.A_T, axis=0)[::-1, :][:topn_a, :]]\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " [[0, 0, 0, 1, 2, 1],\n",
       "  [0, 0, 1, 1, 1, 1, 1],\n",
       "  [2, 2, 2, 3, 3, 3],\n",
       "  [0, 2, 2, 2, 3, 3, 1],\n",
       "  [4, 4, 4, 0, 5, 5, 2],\n",
       "  [4, 5, 5, 3, 0, 5, 5, 1]],\n",
       " [[0, 1], [1, 2], [0, 1, 2], [2, 3], [4, 5, 3], [4, 5]],\n",
       " array(['V0', 'V1', 'V2', 'V3', 'V4', 'V5'], \n",
       "       dtype='|S2'),\n",
       " array(['A0', 'A1', 'A2', 'A3', 'A4', 'A5'], \n",
       "       dtype='|S2'))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 3\n",
    "doc_word_matrix = [[0,0,0,1,2,1],\n",
    "                  [0,0,1,1,1,1,1],\n",
    "                  [2,2,2,3,3,3],\n",
    "                  [0,2,2,2,3,3,1],\n",
    "                  [4,4,4,0,5,5,2],\n",
    "                  [4,5,5,3,0,5,5,1]]\n",
    "doc_author_matrix = [[0,1],\n",
    "                     [1,2],\n",
    "                     [0,1,2],\n",
    "                     [2,3],\n",
    "                     [4,5,3],\n",
    "                     [4,5]]\n",
    "vocab = np.array([\"V%s\" % k for k in xrange(6)])\n",
    "authornames = np.array([\"A%s\" % k for k in xrange(6)])\n",
    "\n",
    "K, doc_word_matrix, doc_author_matrix, vocab, authornames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "atm = AuthorTopicModel(K, doc_word_matrix, doc_author_matrix, vocab, authornames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 100 gibbs sampling iterations burn in phase\n",
      "Burn in complete\n",
      "Topic proportions: [ 0.24390244  0.51219512  0.24390244]\n",
      "Author proportions: [ 0.19512195  0.14634146  0.14634146  0.14634146  0.2195122   0.14634146]\n",
      "W_T[w,z]:\n",
      "[[ 0.02439024  0.14634146  0.02439024]\n",
      " [ 0.          0.12195122  0.09756098]\n",
      " [ 0.04878049  0.04878049  0.09756098]\n",
      " [ 0.          0.12195122  0.02439024]\n",
      " [ 0.09756098  0.          0.        ]\n",
      " [ 0.07317073  0.07317073  0.        ]]\n",
      "A_T[a,z]:\n",
      "[[ 0.          0.17073171  0.02439024]\n",
      " [ 0.02439024  0.12195122  0.        ]\n",
      " [ 0.          0.07317073  0.07317073]\n",
      " [ 0.          0.          0.14634146]\n",
      " [ 0.2195122   0.          0.        ]\n",
      " [ 0.          0.14634146  0.        ]]\n",
      "Performing 10 gibbs sampling iterations\n",
      "Iter 0:\n",
      "Topic proportions: [ 0.24390244  0.48780488  0.26829268]\n",
      "Author proportions: [ 0.12195122  0.19512195  0.24390244  0.12195122  0.24390244  0.07317073]\n",
      "W_T[w,z]:\n",
      "[[ 0.          0.12195122  0.07317073]\n",
      " [ 0.          0.14634146  0.07317073]\n",
      " [ 0.          0.12195122  0.07317073]\n",
      " [ 0.          0.09756098  0.04878049]\n",
      " [ 0.09756098  0.          0.        ]\n",
      " [ 0.14634146  0.          0.        ]]\n",
      "A_T[a,z]:\n",
      "[[ 0.          0.09756098  0.02439024]\n",
      " [ 0.          0.19512195  0.        ]\n",
      " [ 0.          0.12195122  0.12195122]\n",
      " [ 0.          0.          0.12195122]\n",
      " [ 0.24390244  0.          0.        ]\n",
      " [ 0.          0.07317073  0.        ]]\n",
      "Iter 5:\n",
      "Topic proportions: [ 0.17073171  0.58536585  0.24390244]\n",
      "Author proportions: [ 0.09756098  0.17073171  0.29268293  0.12195122  0.17073171  0.14634146]\n",
      "W_T[w,z]:\n",
      "[[ 0.          0.09756098  0.09756098]\n",
      " [ 0.          0.2195122   0.        ]\n",
      " [ 0.          0.17073171  0.02439024]\n",
      " [ 0.          0.04878049  0.09756098]\n",
      " [ 0.04878049  0.04878049  0.        ]\n",
      " [ 0.12195122  0.          0.02439024]]\n",
      "A_T[a,z]:\n",
      "[[ 0.          0.09756098  0.        ]\n",
      " [ 0.          0.17073171  0.        ]\n",
      " [ 0.          0.2195122   0.07317073]\n",
      " [ 0.          0.          0.12195122]\n",
      " [ 0.17073171  0.          0.        ]\n",
      " [ 0.          0.09756098  0.04878049]]\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "atm.perform_iterations(max_iters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 words per topic\n",
      "[['V5' 'V1' 'V3']\n",
      " ['V4' 'V2' 'V0']\n",
      " ['V3' 'V0' 'V5']]\n",
      "Top 3 authors per topic\n",
      "[['A4' 'A2' 'A3']\n",
      " ['A5' 'A1' 'A2']\n",
      " ['A3' 'A5' 'A5']]\n"
     ]
    }
   ],
   "source": [
    "atm.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
